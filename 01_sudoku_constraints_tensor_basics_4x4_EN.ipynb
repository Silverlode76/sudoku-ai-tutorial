{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2e0592e",
   "metadata": {},
   "source": [
    "# Sudoku Constraints with Tensors (4×4)\n",
    "\n",
    "This notebook explains step by step how to build the following loss terms (row / column / block / givens) **using concrete examples**:\n",
    "\n",
    "- `row_sum = P.sum(dim=1)`\n",
    "- `col_sum = P.sum(dim=0)`\n",
    "- block slicing + `reshape`\n",
    "- givens masking + `nll_loss(log(P))`\n",
    "\n",
    "We work with a **4×4 Sudoku** (digits 1..4) and **2×2 blocks** to keep the tensor operations transparent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bed141c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.set_printoptions(precision=2, sci_mode=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "071a87b3",
   "metadata": {},
   "source": [
    "## 1) What is `P`?\n",
    "\n",
    "`P` is a probability tensor with shape `(4, 4, 4)`:\n",
    "\n",
    "- `P[r, c, k]` = probability that cell `(r, c)` contains digit `(k + 1)`.\n",
    "\n",
    "For each cell we require:\n",
    "\n",
    "\\[\n",
    "\\sum_k P[r, c, k] = 1\n",
    "\\]\n",
    "\n",
    "### Example\n",
    "\n",
    "We have a Sudoku grid where `0` means “unknown”:\n",
    "\n",
    "```\n",
    "[1, 2, 3, 4]\n",
    "[0, 0, 0, 0]\n",
    "[0, 0, 0, 0]\n",
    "[0, 0, 0, 0]\n",
    "```\n",
    "\n",
    "To represent digits as probabilities, we extend the 4×4 grid `(r × c)` into a 4×4×4 tensor `(r × c × k)`.\n",
    "You can visualize this tensor as a cube.\n",
    "\n",
    "![4×4×4 Sudoku as a tensor cube](images/Cube4x4x4.jpg)\n",
    "\n",
    "If we translate this idea to `P`, we get the following cube:\n",
    "\n",
    "<img src=\"images/CubeP_4x4x4.jpg\" alt=\"4×4×4 Sudoku as a probability tensor cube P\" width=\"200\"/>\n",
    "\n",
    "- Gray cubes represent a probability of `0.25` (uniform uncertainty)\n",
    "- Beige cubes represent `0.0`\n",
    "- Black cubes represent given digits with value `1.0`\n",
    "\n",
    "In the next step we sum over the digit dimension `k`, so we end up with a matrix of shape `(r × c)`.\n",
    "Ideally, the sum over `k` should always be `1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def4a51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple example for P:\n",
    "# - row 0 is fixed and correct (one-hot per cell)\n",
    "# - all other cells are initialized uniformly (0.25 per digit)\n",
    "\n",
    "P = torch.zeros(4,4,4)\n",
    "\n",
    "# Row 0: [1,2,3,4] as one-hot\n",
    "P[0,0,0] = 1\n",
    "P[0,1,1] = 1\n",
    "P[0,2,2] = 1\n",
    "P[0,3,3] = 1\n",
    "\n",
    "# Remaining cells: uniform uncertainty\n",
    "P[1:,:,:] = 0.25\n",
    "print(\"P[0,0,k] =\", P[0,0,:], \"Sum_P[0,0,:] =\", P[0,0,:].sum())\n",
    "print(\"P[0,1,k] =\", P[0,1,:], \"Sum_P[0,1,:] =\", P[0,1,:].sum())\n",
    "print(\"P[0,2,k] =\", P[0,2,:], \"Sum_P[0,2,:] =\", P[0,2,:].sum())\n",
    "print(\"P[0,3,k] =\", P[0,3,:], \"Sum_P[0,3,:] =\", P[0,3,:].sum())\n",
    "\n",
    "print(\"P[1,0,k] =\", P[1,0,:], \"Sum_P[1,0,:] =\", P[1,0,:].sum())\n",
    "print(\"P[1,1,k] =\", P[1,1,:], \"Sum_P[1,1,:] =\", P[1,1,:].sum())\n",
    "print(\"P[1,2,k] =\", P[1,2,:], \"Sum_P[1,2,:] =\", P[1,2,:].sum())\n",
    "print(\"P[1,3,k] =\", P[1,3,:], \"Sum_P[1,3,:] =\", P[1,3,:].sum())\n",
    "\n",
    "print(\"P[2,0,k] =\", P[2,0,:], \"Sum_P[2,0,:] =\", P[2,0,:].sum())\n",
    "print(\"P[2,1,k] =\", P[2,1,:], \"Sum_P[2,1,:] =\", P[2,1,:].sum())\n",
    "print(\"P[2,2,k] =\", P[2,2,:], \"Sum_P[2,2,:] =\", P[2,2,:].sum())\n",
    "print(\"P[2,3,k] =\", P[2,3,:], \"Sum_P[2,3,:] =\", P[2,3,:].sum())\n",
    "\n",
    "print(\"P[3,0,k] =\", P[3,0,:], \"Sum_P[3,0,:] =\", P[3,0,:].sum())\n",
    "print(\"P[3,1,k] =\", P[3,1,:], \"Sum_P[3,1,:] =\", P[3,1,:].sum())\n",
    "print(\"P[3,2,k] =\", P[3,2,:], \"Sum_P[3,2,:] =\", P[3,2,:].sum())\n",
    "print(\"P[3,3,k] =\", P[3,3,:], \"Sum_P[3,3,:] =\", P[3,3,:].sum())\n",
    "\n",
    "# Check: each cell sums over k to 1\n",
    "cell_sums = P.sum(dim=2)\n",
    "cell_sums"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bc0581",
   "metadata": {},
   "source": [
    "If everything is consistent, `cell_sums` should be `1.0` everywhere."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64a0c6f",
   "metadata": {},
   "source": [
    "## 2) Row Constraint (Row Uniqueness)\n",
    "\n",
    "For each row `r` and each digit `k`:\n",
    "\n",
    "\\[\n",
    "\\sum_c P[r, c, k] = 1\n",
    "\\]\n",
    "\n",
    "Interpretation: In a row, each digit (1..4) should appear **exactly once**.\n",
    "\n",
    "<img src=\"images/CubeP_4x4x4.jpg\" alt=\"4×4×4 Sudoku as a probability tensor cube P\" width=\"200\"/>\n",
    "\n",
    "- Gray cubes represent a probability of `0.25`\n",
    "- Beige cubes represent `0.0`\n",
    "- Black cubes represent given digits with value `1.0`\n",
    "\n",
    "In the following example we sum over the column dimension `c`, resulting in a matrix of shape `(r × k)`.\n",
    "Ideally, the sum over `c` should be `1` for every `(r, k)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd7451a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"P[0,j,0] =\", P[0,:,0], \"Sum_P[0,:,0] =\", P[0,:,0].sum())\n",
    "print(\"P[0,j,1] =\", P[0,:,1], \"Sum_P[0,:,1] =\", P[0,:,1].sum())\n",
    "print(\"P[0,j,2] =\", P[0,:,2], \"Sum_P[0,:,2] =\", P[0,:,2].sum())\n",
    "print(\"P[0,j,3] =\", P[0,:,3], \"Sum_P[0,:,3] =\", P[0,:,3].sum())\n",
    "\n",
    "print(\"P[1,j,0] =\", P[1,:,0], \"Sum_P[1,:,0] =\", P[1,:,0].sum())\n",
    "print(\"P[1,j,1] =\", P[1,:,1], \"Sum_P[1,:,1] =\", P[1,:,1].sum())\n",
    "print(\"P[1,j,2] =\", P[1,:,2], \"Sum_P[1,:,2] =\", P[1,:,2].sum())\n",
    "print(\"P[1,j,3] =\", P[1,:,3], \"Sum_P[1,:,3] =\", P[1,:,3].sum())\n",
    "\n",
    "print(\"P[2,j,0] =\", P[2,:,0], \"Sum_P[2,:,0] =\", P[2,:,0].sum())\n",
    "print(\"P[2,j,1] =\", P[2,:,1], \"Sum_P[2,:,1] =\", P[2,:,1].sum())\n",
    "print(\"P[2,j,2] =\", P[2,:,2], \"Sum_P[2,:,2] =\", P[2,:,2].sum())\n",
    "print(\"P[2,j,3] =\", P[2,:,3], \"Sum_P[2,:,3] =\", P[2,:,3].sum())\n",
    "\n",
    "print(\"P[3,j,0] =\", P[3,:,0], \"Sum_P[3,:,0] =\", P[3,:,0].sum())\n",
    "print(\"P[3,j,1] =\", P[3,:,1], \"Sum_P[3,:,1] =\", P[3,:,1].sum())\n",
    "print(\"P[3,j,2] =\", P[3,:,2], \"Sum_P[3,:,2] =\", P[3,:,2].sum())\n",
    "print(\"P[3,j,3] =\", P[3,:,3], \"Sum_P[3,:,3] =\", P[3,:,3].sum())\n",
    "\n",
    "row_sum = P.sum(dim=1)  # Summe über Spalten j\n",
    "row_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995f7158",
   "metadata": {},
   "source": [
    "- `P` has shape `(4, 4, 4)`\n",
    "- `P.sum(dim=1)` sums over the **columns** ⇒ output shape `(4, 4)` = `(rows, digits)`\n",
    "\n",
    "`row_sum[i, k]` tells you: *How much total probability does row `i` assign to digit `k`?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dab8626",
   "metadata": {},
   "outputs": [],
   "source": [
    "L_row = ((row_sum - 1.0) ** 2).sum()\n",
    "L_row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875d556d",
   "metadata": {},
   "source": [
    "The row loss is `0` if **every** row has sum `1` for **every** digit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8f81d8",
   "metadata": {},
   "source": [
    "## 3) Column Constraint (Column Uniqueness)\n",
    "\n",
    "For each column `c` and each digit `k`:\n",
    "\n",
    "\\[\n",
    "\\sum_r P[r, c, k] = 1\n",
    "\\]\n",
    "\n",
    "Interpretation: In a column, each digit (1..4) should appear **exactly once**.\n",
    "\n",
    "<img src=\"images/CubeP_4x4x4.jpg\" alt=\"4×4×4 Sudoku as a probability tensor cube P\" width=\"200\"/>\n",
    "\n",
    "- Gray cubes represent a probability of `0.25`\n",
    "- Beige cubes represent `0.0`\n",
    "- Black cubes represent given digits with value `1.0`\n",
    "\n",
    "In the following example we sum over the row dimension `r`, resulting in a matrix of shape `(c × k)`.\n",
    "Ideally, the sum over `r` should be `1` for every `(c, k)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af82f35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"P[i,0,0] =\", P[:,0,0], \"Sum_P[:,0,0] =\", P[:,0,0].sum())\n",
    "print(\"P[i,0,1] =\", P[:,0,1], \"Sum_P[:,0,1] =\", P[:,0,1].sum())\n",
    "print(\"P[i,0,2] =\", P[:,0,2], \"Sum_P[:,0,2] =\", P[:,0,2].sum())\n",
    "print(\"P[i,0,3] =\", P[:,0,3], \"Sum_P[:,0,3] =\", P[:,0,3].sum())\n",
    "\n",
    "print(\"P[i,1,0] =\", P[:,1,0], \"Sum_P[:,1,0] =\", P[:,1,0].sum())\n",
    "print(\"P[i,1,1] =\", P[:,1,1], \"Sum_P[:,1,1] =\", P[:,1,1].sum())\n",
    "print(\"P[i,1,2] =\", P[:,1,2], \"Sum_P[:,1,2] =\", P[:,1,2].sum())\n",
    "print(\"P[i,1,3] =\", P[:,1,3], \"Sum_P[:,1,3] =\", P[:,1,3].sum())\n",
    "\n",
    "print(\"P[i,2,0] =\", P[:,2,0], \"Sum_P[:,2,0] =\", P[:,2,0].sum())\n",
    "print(\"P[i,2,1] =\", P[:,2,1], \"Sum_P[:,2,1] =\", P[:,2,1].sum())\n",
    "print(\"P[i,2,2] =\", P[:,2,2], \"Sum_P[:,2,2] =\", P[:,2,2].sum())\n",
    "print(\"P[i,2,3] =\", P[:,2,3], \"Sum_P[:,2,3] =\", P[:,2,3].sum())\n",
    "\n",
    "print(\"P[i,3,0] =\", P[:,3,0], \"Sum_P[:,3,0] =\", P[:,3,0].sum())\n",
    "print(\"P[i,3,1] =\", P[:,3,1], \"Sum_P[:,3,1] =\", P[:,3,1].sum())\n",
    "print(\"P[i,3,2] =\", P[:,3,2], \"Sum_P[:,3,2] =\", P[:,3,2].sum())\n",
    "print(\"P[i,3,3] =\", P[:,3,3], \"Sum_P[:,3,3] =\", P[:,3,3].sum())\n",
    "\n",
    "col_sum = P.sum(dim=0)  # Summe über Zeilen i\n",
    "col_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf51dc7f",
   "metadata": {},
   "source": [
    "- `P.sum(dim=0)` sums over the **rows** ⇒ output shape `(4, 4)` = `(cols, digits)`\n",
    "\n",
    "`col_sum[j, k]` tells you: *How much total probability does column `j` assign to digit `k`?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c038d054",
   "metadata": {},
   "outputs": [],
   "source": [
    "L_col = ((col_sum - 1.0) ** 2).sum()\n",
    "L_col"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5fc39a",
   "metadata": {},
   "source": [
    "## 4) Block Constraint (2×2 Blocks)\n",
    "\n",
    "For each 2×2 block `b` and each digit `k`:\n",
    "\n",
    "\\[\n",
    "\\sum_{(r,c) \\in b} P[r, c, k] = 1\n",
    "\\]\n",
    "\n",
    "We extract blocks via slicing and sum over the 4 cells of each block.\n",
    "\n",
    "<img src=\"images/CubeP_BLK_4x4x4.jpg\" alt=\"4×4×4 Sudoku as a probability tensor cube P\" width=\"400\"/>\n",
    "\n",
    "- Gray cubes represent a probability of `0.25`\n",
    "- Beige cubes represent `0.0`\n",
    "- Black cubes represent given digits with value `1.0`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8696fa09",
   "metadata": {},
   "source": [
    "### 4.1) Inspect a block (top-left)\n",
    "\n",
    "The top-left block covers rows `0..1` and columns `0..1`.\n",
    "\n",
    "<img src=\"images/CubeBLK_2x2x4.jpg\" alt=\"4×4×4 Sudoku as a probability tensor cube P\" width=\"200\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc02183",
   "metadata": {},
   "outputs": [],
   "source": [
    "blk = P[0:2, 0:2, :]   # (2,2,4)\n",
    "\n",
    "print(\"blk[0,0,:] =\", blk[0,0,:])\n",
    "print(\"blk[0,1,:] =\", blk[0,1,:])\n",
    "print(\"blk[1,0,:] =\", blk[1,0,:])\n",
    "print(\"blk[1,1,:] =\", blk[1,1,:])\n",
    "\n",
    "blk.shape, blk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ef6bc4",
   "metadata": {},
   "source": [
    "### 4.2) Flatten the block + sum per digit\n",
    "\n",
    "We want to treat the four cells of the block as a list (`N = 4`):\n",
    "\n",
    "- `blk.reshape(-1, 4)` converts `(2, 2, 4) → (4, 4)`\n",
    "- then we sum over the 4 cells (`dim=0`) ⇒ output shape `(4,)` (one sum per digit)\n",
    "\n",
    "<img src=\"images/CubeBLK_4x4.jpg\" alt=\"4×4×4 Sudoku as a probability tensor cube P\" width=\"200\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940ad268",
   "metadata": {},
   "outputs": [],
   "source": [
    "blk_flat = blk.reshape(-1, 4)     # (4,4)\n",
    "\n",
    "blk_sum  = blk_flat.sum(dim=0)    # (4,)\n",
    "blk_flat.shape, blk_flat, blk_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2f6f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "blk_loss = ((blk_sum - 1.0) ** 2).sum()\n",
    "blk_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea4d84b",
   "metadata": {},
   "source": [
    "### 4.3) Iterate over all 2×2 blocks\n",
    "\n",
    "For a 4×4 Sudoku with 2×2 blocks, block rows start at `br = 0, 2` and block columns at `bc = 0, 2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf6a189",
   "metadata": {},
   "outputs": [],
   "source": [
    "L_blk = 0.0\n",
    "for br in range(0, 4, 2):\n",
    "    for bc in range(0, 4, 2):\n",
    "        print(br, bc)\n",
    "        blk = P[br:br+2, bc:bc+2, :]       # (2,2,4)\n",
    "        blk_sum = blk.reshape(-1, 4).sum(dim=0)  # (4,)\n",
    "        L_blk = L_blk + ((blk_sum - 1.0) ** 2).sum()\n",
    "\n",
    "L_blk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e276802",
   "metadata": {},
   "source": [
    "## 5) Givens Constraint (Hard Clues)\n",
    "\n",
    "`puzzle` contains:\n",
    "\n",
    "- `0` = empty\n",
    "- `1..4` = given digit (clue)\n",
    "\n",
    "We build:\n",
    "\n",
    "- `givens_mask = puzzle > 0` (boolean mask)\n",
    "- `givens_target = puzzle - 1` (0-based classes: `0..3`)\n",
    "\n",
    "Then:\n",
    "\n",
    "- collect the probabilities of the given cells: `given_P = P[givens_mask]` → shape `(Ngivens, 4)`\n",
    "- collect the correct class indices: `targets = givens_target[givens_mask]` → shape `(Ngivens,)`\n",
    "\n",
    "<img src=\"images/given_P.jpg\" alt=\"4×4×4 Sudoku as a probability tensor cube P\" width=\"200\"/>\n",
    "\n",
    "Loss: `nll_loss(log(P), targets)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94684a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "puzzle = torch.tensor([\n",
    "    [1, 2, 3, 4],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 0, 0]\n",
    "])\n",
    "\n",
    "givens_mask = puzzle > 0\n",
    "givens_target = puzzle.clamp(min=1) - 1  # 1..4 -> 0..3; 0 wird durch clamp sicher gemacht\n",
    "\n",
    "puzzle, givens_mask, givens_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9c7224",
   "metadata": {},
   "outputs": [],
   "source": [
    "given_P = P[givens_mask]                 # (Ngivens, 4)\n",
    "targets = givens_target[givens_mask]     # (Ngivens,)\n",
    "given_P.shape, given_P, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3123559",
   "metadata": {},
   "source": [
    "### Why `clamp(min=1)`?\n",
    "\n",
    "Because empty cells are `0`, and `0 - 1` would become `-1` (invalid index).\n",
    "\n",
    "Important: empty cells are excluded by `givens_mask` anyway, so their target value does not matter for the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8df002",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-9\n",
    "if givens_mask.any():\n",
    "    print(\"log.given_P[0,0]+eps =\", (given_P[0,0]+eps).log())\n",
    "    print(\"log.given_P[1,1]+eps =\", (given_P[1,1]+eps).log())\n",
    "    print(\"log.given_P[2,2]+eps =\", (given_P[2,2]+eps).log())\n",
    "    print(\"log.given_P[3,3]+eps =\", (given_P[3,3]+eps).log())\n",
    "    L_giv = F.nll_loss((given_P + eps).log(), targets, reduction=\"sum\")\n",
    "else:\n",
    "    L_giv = P.new_tensor(0.0)\n",
    "\n",
    "L_giv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c58525a-c372-48a9-9b3b-b5bf7bcebe14",
   "metadata": {},
   "source": [
    "## 7) Entropy Loss (Encouraging Confident Predictions)\n",
    "\n",
    "In addition to the structural constraints, we introduce an **entropy loss** that controls the uncertainty of the probability tensor `P`.\n",
    "\n",
    "For a single cell `(r, c)`, the entropy of the probability distribution over digits is defined as:\n",
    "\n",
    "\\[\n",
    "H(P[r,c,:]) = - \\sum_k P[r,c,k] \\log(P[r,c,k])\n",
    "\\]\n",
    "\n",
    "In code, this is computed as:\n",
    "\n",
    "```python\n",
    "ent = -(P * (P + eps).log()).sum(dim=2)  # shape: (rows, columns)\n",
    "L_ent = ent.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88bb7f6-a4d0-42cc-8d88-365746e74245",
   "metadata": {},
   "outputs": [],
   "source": [
    "ent = -(P * (P + eps).log()).sum(dim=2)  # (9,9)\n",
    "L_ent = ent.sum()\n",
    "\n",
    "-(P * (P + eps).log()), ent, L_ent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c7358b",
   "metadata": {},
   "source": [
    "## 8) Total Loss (Example)\n",
    "\n",
    "You can weight the individual parts and sum them into a single scalar loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54766e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_row, w_col, w_blk, w_giv, w_ent = 1.0, 1.0, 1.0, 2.0, 0.01\n",
    "L_total = w_row*L_row + w_col*L_col + w_blk*L_blk + w_giv*L_giv + w_ent*L_ent\n",
    "L_row, L_col, L_blk, L_giv, L_total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e2e31f",
   "metadata": {},
   "source": [
    "## 7) Mini Experiment: Create a Row Error on Purpose\n",
    "\n",
    "We break row 0 by assigning the same digit to two cells.\n",
    "\n",
    "<img src=\"images/P_bad.jpg\" alt=\"4×4×4 Sudoku as a probability tensor cube P\" width=\"200\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd47896",
   "metadata": {},
   "outputs": [],
   "source": [
    "P_bad = P.clone()\n",
    "# Set (0,2) also to digit 2 (index 1) instead of 3 (index 2)\n",
    "P_bad[0,2,:] = 0\n",
    "P_bad[0,2,1] = 1\n",
    "\n",
    "row_sum_bad = P_bad.sum(dim=1)\n",
    "L_row_bad = ((row_sum_bad - 1.0) ** 2).sum()\n",
    "row_sum_bad, L_row, L_row_bad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d2dee7",
   "metadata": {},
   "source": [
    "You can see: as soon as a digit gets *too much* probability within a row, the row loss increases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f45072-f148-4f4c-99af-7f9749a16dec",
   "metadata": {},
   "source": [
    "## 8) Effect of Violating a Given Cell\n",
    "\n",
    "In this example, we deliberately violate one of the given cells by assigning it a very low probability for the correct digit.\n",
    "This allows us to observe how the **givens loss reacts to hard constraint violations**.\n",
    "\n",
    "First, we extract only the probabilities and targets corresponding to the given cells:\n",
    "\n",
    "- `given_P_bad` contains the predicted probabilities for the given cells\n",
    "\n",
    "<img src=\"images/P_given_bad.jpg\" alt=\"4×4×4 Sudoku as a probability tensor cube P\" width=\"200\"/>\n",
    "\n",
    "- `targets` contains the correct digit indices for those cells\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b589dc5f-cd4a-4afe-ae27-20ac122bc739",
   "metadata": {},
   "outputs": [],
   "source": [
    "given_P_bad = P_bad[givens_mask]                 # (Ngivens, 4)\n",
    "targets = givens_target[givens_mask]     # (Ngivens,)\n",
    "given_P.shape, given_P_bad, targets\n",
    "\n",
    "eps = 1e-9\n",
    "if givens_mask.any():\n",
    "    print(\"log.given_P_bad[0,0]+eps =\", (given_P_bad[0,0]+eps).log())\n",
    "    print(\"log.given_P_bad[1,1]+eps =\", (given_P_bad[1,1]+eps).log())\n",
    "    print(\"log.given_P_bad[2,2]+eps =\", (given_P_bad[2,2]+eps).log())\n",
    "    print(\"log.given_P_bad[3,3]+eps =\", (given_P_bad[3,3]+eps).log())\n",
    "    L_giv = F.nll_loss((given_P_bad+ eps).log(), targets, reduction=\"sum\")\n",
    "else:\n",
    "    L_giv = P.new_tensor(0.0)\n",
    "\n",
    "L_giv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea44f26-63e5-4f77-8552-018c9d39bbf3",
   "metadata": {},
   "source": [
    "You can see: the loss of P_bad[2,2] is very high because its value is 0. We would expect a value of 1.0 for a correct solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f5172b-59c5-4d20-8592-73f6385bc668",
   "metadata": {},
   "source": [
    "## Conclusion: Why the Givens Loss Dominates\n",
    "\n",
    "**Observation:**  \n",
    "In the examples above, the *givens loss* increases much more strongly than the row, column, or block losses when a given cell is violated.\n",
    "\n",
    "This is **intentional**.\n",
    "\n",
    "Given digits (“givens”) are **hard constraints**: they must never be violated.\n",
    "Row, column, and block constraints mainly enforce *structural consistency*, while givens restrict the solution space.\n",
    "\n",
    "Mathematically, this difference comes from the loss formulation:\n",
    "\n",
    "- **Row / Column / Block losses** are quadratic penalties and grow *gradually* with the constraint violation.\n",
    "- **Givens loss** is a **negative log-likelihood**. As soon as the correct digit gets very small probability in a given cell, the loss grows rapidly (logarithmically towards ∞).\n",
    "\n",
    "**Intuition:**\n",
    "- Constraint losses say: *“This solution is structurally inconsistent.”*\n",
    "- Givens loss says: *“This solution is wrong.”*\n",
    "\n",
    "At this point we have defined what a valid Sudoku solution means — but not yet **how** to minimize these losses.\n",
    "That is the topic of the next chapter, where we introduce the optimization algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5a76f5-dfb6-4583-b993-952a164f2f69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
