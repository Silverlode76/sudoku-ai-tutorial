{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 4\u00d74 Sudoku with Only Row/Column/Block Losses\n\n",
        "This notebook demonstrates why row, column, and block losses alone do not solve the 4\u00d74 Sudoku.\n",
        "With uniform logits the constraint losses already drop to zero, yet the puzzle is unsolved because:\n\n",
        "- the givens are not enforced, and\n",
        "- the probabilities keep high entropy instead of collapsing to single digits.\n\n",
        "The example mirrors the puzzle used in the README."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "We start with zero logits so each cell has a uniform probability over the four digits.\n",
        "The given clues are only recorded for evaluation; they are **not** part of the loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n\n",
        "# Fixed 4\u00d74 Sudoku clues (1-based values; zero means empty)\n",
        "puzzle = torch.tensor([\n",
        "    [0, 0, 0, 4],\n",
        "    [0, 2, 0, 0],\n",
        "    [1, 0, 0, 0],\n",
        "    [0, 0, 3, 0],\n",
        "])\n",
        "given_mask = puzzle > 0\n\n",
        "# Start with zero logits -> uniform probabilities after softmax\n",
        "digits = 4\n",
        "Z = torch.zeros(4, 4, digits)\n",
        "P = F.softmax(Z, dim=2)\n",
        "print(P[0, 0])  # one cell is uniform\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Row/Column/Block losses\n",
        "With uniform probabilities, the Sudoku constraints already yield zero loss:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def block_sums(P):\n",
        "    # Reshape into 2\u00d72 blocks and sum within each block over rows/cols\n",
        "    return P.view(2, 2, 2, 2, digits).sum(dim=(1, 3))\n\n",
        "row_sum = P.sum(dim=1)\n",
        "col_sum = P.sum(dim=0)\n",
        "blocks = block_sums(P)\n\n",
        "L_row = ((row_sum - 1.0) ** 2).sum()\n",
        "L_col = ((col_sum - 1.0) ** 2).sum()\n",
        "L_block = ((blocks - 1.0) ** 2).sum()\n\n",
        "print(f\"L_row={L_row.item():.4f}, L_col={L_col.item():.4f}, L_block={L_block.item():.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## What the optimizer would see\n",
        "Because all three losses are already zero, gradient descent would stop immediately. Yet the grid neither respects the givens nor commits to single digits."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Adding a givens loss\n",
        "Row/column/block losses ignore the clues. A givens loss keeps each preset cell close to its target digit.\n",
        "Here we use a simple mean-squared error against the one-hot digit for every given."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build one-hot targets for all cells (zeros stay unused for loss)\n",
        "targets = F.one_hot(puzzle.clamp(min=1) - 1, num_classes=digits).float()\n\n",
        "# Penalize deviation from the given digits only where clues exist\n",
        "L_givens = ((P[given_mask] - targets[given_mask]) ** 2).sum()\n",
        "total_loss = L_row + L_col + L_block + L_givens\n\n",
        "print(f'Givens loss: {L_givens.item():.4f}')\n",
        "print(f'Total loss with givens: {total_loss.item():.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With uniform probabilities, the givens loss is the only non-zero term.\n",
        "It forces optimization to move the preset cells toward their clues,\n",
        "so the combined loss no longer stalls at zero. An entropy or sharpening\n",
        "term is still needed to collapse each cell to a single digit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# The \"solution\" implied by argmax is arbitrary (always digit 1 here)\n",
        "solution = P.argmax(dim=2) + 1\n\n",
        "# Check how many givens are satisfied\n",
        "correct_givens = (solution[given_mask] == puzzle[given_mask]).sum().item()\n",
        "total_givens = given_mask.sum().item()\n\n",
        "# Measure mean entropy per cell to show probabilities are not one-hot\n",
        "entropy = -(P * P.log()).sum(dim=2).mean()\n\n",
        "print(solution)\n",
        "print(f\"Givens satisfied: {correct_givens}/{total_givens}\")\n",
        "print(f\"Mean entropy per cell: {entropy.item():.3f} nats\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Takeaway\n",
        "Row, column, and block losses alone cannot solve the puzzle.\n",
        "They are already minimized by a uniform distribution that ignores the givens.\n\n",
        "To actually solve the Sudoku we still need:\n",
        "- a **givens loss** to force the clues, and\n",
        "- an **entropy or sharpening term** (or low temperature) so each cell collapses to one digit."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}